{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n",
      "/Users/ismaelrobles-razzaq/Desktop/research/.venv/lib/python3.11/site-packages/gym/envs/registration.py:396: UserWarning: \u001b[33mWARN: The `registry.all` method is deprecated. Please use `registry.values` instead.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gym\n",
    "import neurogym as ngym\n",
    "from neurogym.wrappers import ScheduleEnvs\n",
    "from neurogym.utils import scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from neurogym.wrappers.block import MultiEnvs\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "import copy\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Set up the environment\n",
    "envid = 'yang19.dm1-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    'dt': 100,\n",
    "    'hidden_size': 20,\n",
    "    'lr': 1e-3,\n",
    "    'batch_size': 64,\n",
    "    'seq_len': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla dm1 RNN first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "kwargs['timing'] = {\n",
    "                'fixation': 300,\n",
    "                'stimulus': 500,\n",
    "                'decision': 200} # fix timing for discrete trial intervals\n",
    "\n",
    "task_env = ngym.make('yang19.dm1-v0', **kwargs)\n",
    "dataset = ngym.Dataset(task_env, batch_size=64, seq_len=10)\n",
    "env = dataset.env\n",
    "\n",
    "ob_size = env.observation_space.shape[0]\n",
    "act_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, hidden = self.rnn(x)\n",
    "        x = self.linear(out)\n",
    "        return x, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size=env.observation_space.shape[0],\n",
    "          hidden_size=config['hidden_size'],\n",
    "          output_size=act_size)\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=config['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss: 0.0620, Accuracy: 89.84%\n",
      "Epoch 1000, Loss: 0.0604, Accuracy: 90.18%\n",
      "Epoch 1500, Loss: 0.0342, Accuracy: 90.03%\n",
      "Epoch 2000, Loss: 0.0668, Accuracy: 90.17%\n",
      "Epoch 2500, Loss: 0.0390, Accuracy: 90.25%\n",
      "Epoch 3000, Loss: 0.0239, Accuracy: 90.00%\n",
      "Epoch 3500, Loss: 0.0253, Accuracy: 90.17%\n",
      "Epoch 4000, Loss: 0.0719, Accuracy: 90.40%\n",
      "Epoch 4500, Loss: 0.0930, Accuracy: 90.21%\n",
      "Epoch 5000, Loss: 0.0356, Accuracy: 90.60%\n",
      "Epoch 5500, Loss: 0.0349, Accuracy: 90.05%\n",
      "Epoch 6000, Loss: 0.0438, Accuracy: 90.15%\n",
      "Epoch 6500, Loss: 0.0557, Accuracy: 90.46%\n",
      "Epoch 7000, Loss: 0.0221, Accuracy: 90.21%\n",
      "Epoch 7500, Loss: 0.0303, Accuracy: 90.12%\n",
      "Epoch 8000, Loss: 0.0529, Accuracy: 90.43%\n",
      "Epoch 8500, Loss: 0.0397, Accuracy: 90.55%\n",
      "Epoch 9000, Loss: 0.0471, Accuracy: 90.33%\n",
      "Epoch 9500, Loss: 0.0366, Accuracy: 90.30%\n",
      "Epoch 10000, Loss: 0.0340, Accuracy: 90.10%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "net.train()\n",
    "num_epochs = 10000\n",
    "best_loss = float('inf')\n",
    "#patience = 200\n",
    "#no_improve_count = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    inputs, labels = dataset()\n",
    "    inputs = torch.from_numpy(inputs).float().to(device)\n",
    "    labels = torch.from_numpy(labels).long().to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs, _ = net(inputs)\n",
    "    loss = criterion(outputs.view(-1, act_size), labels.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs.data, -1)\n",
    "    total += labels.size(1)\n",
    "    for i in range(labels.size(1)):\n",
    "        if torch.equal(predicted[:, i], labels[:, i]):\n",
    "            correct += 1\n",
    "\n",
    "    avg_loss = total_loss\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    if epoch % 500 == 499:\n",
    "        print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        #no_improve_count = 0\n",
    "        torch.save(net.state_dict(), 'net_accuracy.pth')\n",
    "    '''else:\n",
    "        no_improve_count += 1\n",
    "\n",
    "    if no_improve_count >= patience:\n",
    "        print(f'Early stopping at epoch {epoch}')\n",
    "        break'''\n",
    "\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get activities\n",
    "Use batch size 1 for simplicity?\n",
    "matrix should have input, label, model output, model activity for each unit at each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 1, 33)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = dataset()\n",
    "print(labels.shape)\n",
    "inputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_env = ngym.make('yang19.dm1-v0', **kwargs)\n",
    "dataset = ngym.Dataset(task_env, batch_size=1, seq_len=10)\n",
    "env = dataset.env\n",
    "\n",
    "ob_size = env.observation_space.shape[0]\n",
    "act_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = dataset()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrix(model, dataset, num_trials=10000, timesteps=10):\n",
    "\n",
    "    inputs, labels = dataset()\n",
    "\n",
    "    input_size = inputs.shape[2]\n",
    "    label_size = labels.shape[1]\n",
    "    output_size = 1\n",
    "    hidden_size = config['hidden_size']  \n",
    "    timesteps = labels.shape[0]\n",
    "    print(f\"inputs_size: {input_size}, label_size: {label_size}, output_size: {output_size}, hidden_size: {hidden_size}, timesteps = {timesteps}\")\n",
    "\n",
    "    matrix_size = (num_trials, timesteps, input_size + label_size + output_size + hidden_size)\n",
    "    output_matrix = np.zeros(matrix_size)\n",
    "    model.eval()\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "\n",
    "        inputs, labels = dataset()  \n",
    "\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            hidden_states, _ = model.rnn(inputs)\n",
    "            output, _ = model(inputs)\n",
    "            _, predicted = torch.max(output.data, -1) \n",
    "\n",
    "\n",
    "            for t in range(timesteps):\n",
    "                output_matrix[trial, t, :input_size] = inputs[t, 0, :].numpy()\n",
    "                output_matrix[trial, t, input_size:input_size+label_size] = labels[t].numpy()\n",
    "                output_matrix[trial, t, input_size+label_size:input_size+label_size+output_size] = predicted[t, 0].numpy()\n",
    "                output_matrix[trial, t, -hidden_size:] = hidden_states[0, 0, :].numpy()\n",
    "\n",
    "    return output_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/4b964bn507zc652npm2l2ch80000gn/T/ipykernel_21568/219679984.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load('small_net.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (rnn): RNN(33, 20)\n",
       "  (linear): Linear(in_features=20, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model\n",
    "net = Net(input_size=env.observation_space.shape[0],\n",
    "          hidden_size=config['hidden_size'],\n",
    "          output_size=act_size)\n",
    "\n",
    "net.load_state_dict(torch.load('small_net.pth'))\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/4b964bn507zc652npm2l2ch80000gn/T/ipykernel_16631/3984640189.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs, dtype=torch.float32)\n",
      "/var/folders/9c/4b964bn507zc652npm2l2ch80000gn/T/ipykernel_16631/3984640189.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 17])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check correct output shapes\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden_states, _ = net.rnn(inputs)\n",
    "    output, _ = net(inputs)\n",
    "    _, predicted = torch.max(output.data, -1) \n",
    "predicted.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_size: 33, label_size: 1, output_size: 1, hidden_size: 20, timesteps = 10\n",
      "(10000, 10, 55)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result_matrix = generate_matrix(net, dataset)\n",
    "print(result_matrix.shape)  # Should be (10000, 10, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('small_rnn', result_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for large 20 task vanilla rnn -- 100 length sequence should be good, no need for timestep lineup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dt': 100,\n",
    "    'hidden_size': 256,\n",
    "    'lr': 1e-3,\n",
    "    'batch_size': 16,\n",
    "    'seq_len': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names = ['yang19.go-v0', 'yang19.rtgo-v0', 'yang19.dlygo-v0', 'yang19.anti-v0', 'yang19.rtanti-v0', 'yang19.dlyanti-v0', 'yang19.dm1-v0', 'yang19.dm2-v0', 'yang19.ctxdm1-v0', 'yang19.ctxdm2-v0', 'yang19.multidm-v0', 'yang19.dlydm1-v0', 'yang19.dlydm2-v0', 'yang19.ctxdlydm1-v0', 'yang19.ctxdlydm2-v0', 'yang19.multidlydm-v0', 'yang19.dms-v0', 'yang19.dnms-v0', 'yang19.dmc-v0', 'yang19.dnmc-v0']\n",
    "task_list = []\n",
    "for name in task_names:\n",
    "    task_list.append(ngym.make(name))\n",
    "\n",
    "\n",
    "# Create a schedule for switching between tasks\n",
    "schedule = scheduler.RandomSchedule(n=len(task_list))\n",
    "\n",
    "# Combine the tasks\n",
    "combined_env = ScheduleEnvs(task_list, schedule=schedule, env_input=True)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ngym.Dataset(combined_env, batch_size=16, seq_len=100)\n",
    "env = dataset.env\n",
    "\n",
    "ob_size = env.observation_space.shape[0]\n",
    "act_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network\n",
    "multitask_net = Net(input_size=env.observation_space.shape[0],\n",
    "          hidden_size=config['hidden_size'],\n",
    "          output_size=act_size)\n",
    "multitask_net = multitask_net.to(device)\n",
    "\n",
    "# Set up loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(multitask_net.parameters(), lr=config['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tasks: ['yang19.go-v0', 'yang19.rtgo-v0', 'yang19.dlygo-v0', 'yang19.anti-v0', 'yang19.rtanti-v0', 'yang19.dlyanti-v0', 'yang19.dm1-v0', 'yang19.dm2-v0', 'yang19.ctxdm1-v0', 'yang19.ctxdm2-v0', 'yang19.multidm-v0', 'yang19.dlydm1-v0', 'yang19.dlydm2-v0', 'yang19.ctxdlydm1-v0', 'yang19.ctxdlydm2-v0', 'yang19.multidlydm-v0', 'yang19.dms-v0', 'yang19.dnms-v0', 'yang19.dmc-v0', 'yang19.dnmc-v0']\n",
      "Epoch 200, Loss: 0.0460, Accuracy: 98.94%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m multitask_net(inputs)\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, act_size), labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Desktop/research/.venv/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/research/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/research/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "multitask_net.train()\n",
    "print('Training tasks:', [name for name in task_names])\n",
    "\n",
    "num_epochs = 4000\n",
    "best_loss = float('inf')\n",
    "#patience = 200\n",
    "#no_improve_count = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    multitask_net.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    inputs, labels = dataset()\n",
    "    inputs = torch.from_numpy(inputs).float().to(device)\n",
    "    labels = torch.from_numpy(labels).long().to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs, _ = multitask_net(inputs)\n",
    "    loss = criterion(outputs.view(-1, act_size), labels.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs.data, -1)\n",
    "    total += labels.numel()\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    if epoch % 200 == 199:\n",
    "        print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        #no_improve_count = 0\n",
    "        torch.save(multitask_net.state_dict(), 'multitask_net.pth')\n",
    "    '''else:\n",
    "        no_improve_count += 1\n",
    "\n",
    "    if no_improve_count >= patience:\n",
    "        print(f'Early stopping at epoch {epoch}')\n",
    "        break'''\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(net, task_list, num_trials=10):\n",
    "    net.eval()\n",
    "    env = dataset.env\n",
    "    env.reset()\n",
    "\n",
    "    for i, task in enumerate(task_list):\n",
    "        env.set_i(i)\n",
    "        task_name = task_names[i]\n",
    "        print(f\"\\nAnalyzing task: {task_name}\")\n",
    "\n",
    "        total_correct = 0\n",
    "        total_decisions = 0\n",
    "        non_fixation_correct = 0\n",
    "        non_fixation_decisions = 0\n",
    "\n",
    "        for _ in range(num_trials):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = dataset()\n",
    "                inputs = torch.from_numpy(inputs).float().to(device)\n",
    "                labels = torch.from_numpy(labels).long().to(device)\n",
    "\n",
    "                outputs, _ = net(inputs)\n",
    "\n",
    "                # Convert to numpy and process the entire batch\n",
    "                inputs = inputs.cpu().numpy()\n",
    "                labels = labels.cpu().numpy()\n",
    "                outputs = outputs.cpu().numpy()\n",
    "\n",
    "                # Calculate total accuracy\n",
    "                predictions = np.argmax(outputs, axis=2)\n",
    "                total_correct += np.sum(predictions == labels)\n",
    "                total_decisions += labels.size\n",
    "\n",
    "                # Find non-fixation periods (when fixation input is 0)\n",
    "                non_fixation = inputs[:, :, 0] == 0\n",
    "\n",
    "                # Calculate non-fixation accuracy\n",
    "                non_fixation_predictions = predictions[non_fixation]\n",
    "                non_fixation_labels = labels[non_fixation]\n",
    "                non_fixation_correct += np.sum(non_fixation_predictions == non_fixation_labels)\n",
    "                non_fixation_decisions += non_fixation_labels.size\n",
    "\n",
    "        total_accuracy = total_correct / total_decisions if total_decisions > 0 else 0\n",
    "        non_fixation_accuracy = non_fixation_correct / non_fixation_decisions if non_fixation_decisions > 0 else 0\n",
    "\n",
    "        print(f\"Total accuracy ({total_decisions} decisions): {total_accuracy:.4f}\")\n",
    "        print(f\"Non-fixation accuracy ({non_fixation_decisions} decisions): {non_fixation_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing task: yang19.go-v0\n",
      "Total accuracy (16000 decisions): 0.9840\n",
      "Non-fixation accuracy (3237 decisions): 0.9209\n",
      "\n",
      "Analyzing task: yang19.rtgo-v0\n",
      "Total accuracy (16000 decisions): 0.9846\n",
      "Non-fixation accuracy (3303 decisions): 0.9258\n",
      "\n",
      "Analyzing task: yang19.dlygo-v0\n",
      "Total accuracy (16000 decisions): 0.9819\n",
      "Non-fixation accuracy (3205 decisions): 0.9095\n",
      "\n",
      "Analyzing task: yang19.anti-v0\n",
      "Total accuracy (16000 decisions): 0.9828\n",
      "Non-fixation accuracy (3253 decisions): 0.9152\n",
      "\n",
      "Analyzing task: yang19.rtanti-v0\n",
      "Total accuracy (16000 decisions): 0.9854\n",
      "Non-fixation accuracy (3255 decisions): 0.9284\n",
      "\n",
      "Analyzing task: yang19.dlyanti-v0\n",
      "Total accuracy (16000 decisions): 0.9852\n",
      "Non-fixation accuracy (3211 decisions): 0.9265\n",
      "\n",
      "Analyzing task: yang19.dm1-v0\n",
      "Total accuracy (16000 decisions): 0.9841\n",
      "Non-fixation accuracy (3319 decisions): 0.9235\n",
      "\n",
      "Analyzing task: yang19.dm2-v0\n",
      "Total accuracy (16000 decisions): 0.9819\n",
      "Non-fixation accuracy (3135 decisions): 0.9075\n",
      "\n",
      "Analyzing task: yang19.ctxdm1-v0\n",
      "Total accuracy (16000 decisions): 0.9809\n",
      "Non-fixation accuracy (3180 decisions): 0.9044\n",
      "\n",
      "Analyzing task: yang19.ctxdm2-v0\n",
      "Total accuracy (16000 decisions): 0.9808\n",
      "Non-fixation accuracy (3206 decisions): 0.9039\n",
      "\n",
      "Analyzing task: yang19.multidm-v0\n",
      "Total accuracy (16000 decisions): 0.9820\n",
      "Non-fixation accuracy (3222 decisions): 0.9106\n",
      "\n",
      "Analyzing task: yang19.dlydm1-v0\n",
      "Total accuracy (16000 decisions): 0.9822\n",
      "Non-fixation accuracy (3271 decisions): 0.9132\n",
      "\n",
      "Analyzing task: yang19.dlydm2-v0\n",
      "Total accuracy (16000 decisions): 0.9847\n",
      "Non-fixation accuracy (3239 decisions): 0.9244\n",
      "\n",
      "Analyzing task: yang19.ctxdlydm1-v0\n",
      "Total accuracy (16000 decisions): 0.9835\n",
      "Non-fixation accuracy (3279 decisions): 0.9195\n",
      "\n",
      "Analyzing task: yang19.ctxdlydm2-v0\n",
      "Total accuracy (16000 decisions): 0.9852\n",
      "Non-fixation accuracy (3332 decisions): 0.9292\n",
      "\n",
      "Analyzing task: yang19.multidlydm-v0\n",
      "Total accuracy (16000 decisions): 0.9825\n",
      "Non-fixation accuracy (3046 decisions): 0.9081\n",
      "\n",
      "Analyzing task: yang19.dms-v0\n",
      "Total accuracy (16000 decisions): 0.9809\n",
      "Non-fixation accuracy (3204 decisions): 0.9045\n",
      "\n",
      "Analyzing task: yang19.dnms-v0\n",
      "Total accuracy (16000 decisions): 0.9831\n",
      "Non-fixation accuracy (3087 decisions): 0.9122\n",
      "\n",
      "Analyzing task: yang19.dmc-v0\n",
      "Total accuracy (16000 decisions): 0.9816\n",
      "Non-fixation accuracy (3309 decisions): 0.9108\n",
      "\n",
      "Analyzing task: yang19.dnmc-v0\n",
      "Total accuracy (16000 decisions): 0.9841\n",
      "Non-fixation accuracy (3218 decisions): 0.9211\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(multitask_net, task_list, num_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change batch size to 1 for simplicity\n",
    "task_names = ['yang19.go-v0', 'yang19.rtgo-v0', 'yang19.dlygo-v0', 'yang19.anti-v0', 'yang19.rtanti-v0', 'yang19.dlyanti-v0', 'yang19.dm1-v0', 'yang19.dm2-v0', 'yang19.ctxdm1-v0', 'yang19.ctxdm2-v0', 'yang19.multidm-v0', 'yang19.dlydm1-v0', 'yang19.dlydm2-v0', 'yang19.ctxdlydm1-v0', 'yang19.ctxdlydm2-v0', 'yang19.multidlydm-v0', 'yang19.dms-v0', 'yang19.dnms-v0', 'yang19.dmc-v0', 'yang19.dnmc-v0']\n",
    "task_list = []\n",
    "for name in task_names:\n",
    "    task_list.append(ngym.make(name))\n",
    "\n",
    "\n",
    "# Create a schedule for switching between tasks\n",
    "schedule = scheduler.RandomSchedule(n=len(task_list))\n",
    "\n",
    "# Combine the tasks\n",
    "combined_env = ScheduleEnvs(task_list, schedule=schedule, env_input=True)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ngym.Dataset(combined_env, batch_size=1, seq_len=100)\n",
    "env = dataset.env\n",
    "\n",
    "ob_size = env.observation_space.shape[0]\n",
    "act_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/4b964bn507zc652npm2l2ch80000gn/T/ipykernel_21568/3263536786.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  multitask = torch.load('multitask_net.pth')\n"
     ]
    }
   ],
   "source": [
    "multitask = torch.load('multitask_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_size: 53, label_size: 1, output_size: 1, hidden_size: 256, timesteps = 100\n"
     ]
    }
   ],
   "source": [
    "multitask_matrix = generate_matrix(multitask_net, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('multitask_rnn', multitask_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a sample array\n",
    "original_array = np.random.rand(1000, 1000)\n",
    "\n",
    "# Save using savez_compressed\n",
    "np.savez_compressed('compressed_file.npz', data=original_array)\n",
    "\n",
    "# Load the compressed file\n",
    "loaded_file = np.load('compressed_file.npz')\n",
    "loaded_array = loaded_file['data']\n",
    "\n",
    "# Check if shapes are the same\n",
    "print(\"Original shape:\", original_array.shape)\n",
    "print(\"Loaded shape:\", loaded_array.shape)\n",
    "\n",
    "# Check if contents are the same\n",
    "print(\"Arrays are identical:\", np.array_equal(original_array, loaded_array))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
